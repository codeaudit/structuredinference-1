{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Sampling pose DKF trained on H3.6M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import re\n",
    "import os\n",
    "import addpaths\n",
    "from load import loadDataset\n",
    "import p2d_loader\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "import sys\n",
    "del sys.argv[1:]\n",
    "\n",
    "PFX = './chkpt-ikeadb/'\n",
    "CONFIG_PATH = PFX + 'DKF_lr-8_0000e-04-vm-L-inf-structured-dh-50-ds-10-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-True-ikeadb-acts-config.pkl'\n",
    "WEIGHT_PATH = PFX + 'DKF_lr-8_0000e-04-vm-L-inf-structured-dh-50-ds-10-nl-relu-bs-20-ep-2000-rs-600-ttype-simple_gated-etype-mlp-previnp-False-ar-1_0000e+01-rv-5_0000e-02-nade-False-nt-5000-cond-True-ikeadb-acts-EP175-params.npz'\n",
    "sys.argv.extend('-vm L -cond -infm structured -ds 10 -dh 50 -uid past-only'.split())\n",
    "\n",
    "sys.argv.extend(['-reload', WEIGHT_PATH, '-params', CONFIG_PATH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = loadDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from parse_args_dkf import params\n",
    "from utils.misc import removeIfExists,createIfAbsent,mapPrint,saveHDF5,displayTime\n",
    "from stinfmodel_fast.dkf import DKF\n",
    "import stinfmodel_fast.learning as DKF_learn\n",
    "import stinfmodel_fast.evaluate as DKF_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "act_names = dataset['p2d_action_names']\n",
    "print('Action names: ' + ', '.join(map(str, act_names)))\n",
    "one_hot_acts = {}\n",
    "hot_vec_size = len(act_names)\n",
    "for hot_bit, name in enumerate(act_names):\n",
    "    one_hot_acts[name] = (np.arange(hot_vec_size) == hot_bit)\n",
    "parents = dataset['p2d_parents']\n",
    "print('Parents array: %s' % parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "use_cond = bool(params.get('use_cond', False))\n",
    "params['savedir']+='-ikeadb'\n",
    "# createIfAbsent(params['savedir'])\n",
    "\n",
    "# Add dataset and NADE parameters to \"params\" which will become part of the\n",
    "# model\n",
    "for k in ['dim_observations','data_type']:\n",
    "    params[k] = dataset[k]\n",
    "mapPrint('Options: ',params)\n",
    "if params['use_nade']:\n",
    "    params['data_type']='real_nade'\n",
    "\n",
    "# Remove from params\n",
    "removeIfExists('./NOSUCHFILE')\n",
    "reloadFile = params.pop('reloadFile')\n",
    "pfile=params.pop('paramFile')\n",
    "# paramFile is set inside the BaseClass in theanomodels\n",
    "# to point to the pickle file containing params\"\"\"\n",
    "assert os.path.exists(pfile),pfile+' not found. Need paramfile'\n",
    "print 'Reloading trained model from : ',reloadFile\n",
    "print 'Assuming ',pfile,' corresponds to model'\n",
    "dkf  = DKF(params, paramFile = pfile, reloadFile = reloadFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def smooth_seq(seq):\n",
    "    assert seq.ndim in {2, 3}, seq.shape\n",
    "    if seq.ndim == 3:\n",
    "        rv = np.zeros_like(seq)\n",
    "        for r in range(len(seq)):\n",
    "            rv[r] = p2d_loader.gauss_filter(seq[r], sigma=1.0)\n",
    "        return rv\n",
    "    # 2d, filter whole thing\n",
    "    return p2d_loader.gauss_filter(seq, sigma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if not use_cond:\n",
    "#     # No need to do conditional nonsense!\n",
    "#     oodles_of_samples = dkf.sample(nsamples=50, T=1024)\n",
    "#     sample_X, sample_Z = oodles_of_samples\n",
    "\n",
    "#     print('Output shape: %s' % str(sample_X.shape))\n",
    "#     mu = dataset['h36m_mean'].reshape((1, 1, -1))\n",
    "#     sigma = dataset['h36m_std'].reshape((1, 1, -1))\n",
    "#     real_X = insert_junk_entries(sample_X * sigma + mu)\n",
    "#     dest_dir = './generated/'\n",
    "#     try:\n",
    "#         os.makedirs(dest_dir)\n",
    "#     except OSError:\n",
    "#         pass\n",
    "#     for i, sampled_times in enumerate(real_X):\n",
    "#         dest_fn = os.path.join(dest_dir, 'seq-%i.txt' % i)\n",
    "#         print('Saving %s' % dest_fn)\n",
    "#         np.savetxt(dest_fn, sampled_times, delimiter=',', fmt='%f')\n",
    "\n",
    "#     # Do the same thing, but smoothed\n",
    "#     smooth_dest_dir = './generated-smooth/'\n",
    "#     try:\n",
    "#         os.makedirs(smooth_dest_dir)\n",
    "#     except OSError:\n",
    "#         pass\n",
    "#     for i, sampled_times in enumerate(real_X):\n",
    "#         dest_fn = os.path.join(smooth_dest_dir, 'seq-%i.txt' % i)\n",
    "#         print('Saving %s' % dest_fn)\n",
    "#         smooth_times = smooth_seq(sampled_times)\n",
    "#         np.savetxt(dest_fn, smooth_times, delimiter=',', fmt='%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrape_by_act(poses, actions, one_hot_rep, count, sigma, mu, parents):\n",
    "    # actions should be N*T*A\n",
    "    assert np.prod(one_hot_rep.shape) == one_hot_rep.size, \\\n",
    "        \"one-hot rep must be a vector\"\n",
    "    act_num = np.argmax(one_hot_rep.flatten())\n",
    "    assert actions.ndim == 3, actions.shape\n",
    "    act_nums = np.argmax(actions, axis=2)\n",
    "    assert act_nums.shape == poses.shape[:2], \\\n",
    "        \"mismatched action shape %s and pose shape %s\" \\\n",
    "            % (actions.shape, poses.shape)\n",
    "    # try to find sequences that feature part of the action\n",
    "    has_act = np.nonzero((act_num == act_nums).any(axis=1))\n",
    "    indices = has_act[np.random.permutation(len(has_act))][:count]\n",
    "    if len(indices) < count:\n",
    "        print('Only found %d instances of action with ID %d'\n",
    "              % (len(indices), act_num))\n",
    "    out_data = poses[indices]\n",
    "    return p2d_loader.reconstruct_poses(out_data * sigma + mu, parents)\n",
    "\n",
    "def sanitise_name(name):\n",
    "    # for sanitising filenames\n",
    "    return re.sub(r'[^a-z0-9_-]+', '-', name.lower()).strip('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if use_cond:\n",
    "    seqs_per_act = 9\n",
    "    seq_length = 256\n",
    "    dest_dir = './generated-wacts/'\n",
    "    try:\n",
    "        os.makedirs(dest_dir)\n",
    "    except OSError:\n",
    "        pass\n",
    "        \n",
    "    # start by generating some sequences for each action type\n",
    "    for act_name, one_hot_rep in one_hot_acts.items():\n",
    "        print('Working on action %s' % act_name)\n",
    "        U = np.stack([one_hot_rep] * seq_length, axis=0)\n",
    "        oodles_of_samples = dkf.sample(nsamples=seqs_per_act, T=seq_length, U=U)\n",
    "        sample_X, sample_Z = oodles_of_samples\n",
    "        mu = dataset['p2d_mean'].reshape((1, 1, -1))\n",
    "        sigma = dataset['p2d_std'].reshape((1, 1, -1))\n",
    "        real_X = p2d_loader.reconstruct_poses(sample_X * sigma + mu, parents)\n",
    "        \n",
    "        # Scrape some training poses, too\n",
    "        train_poses = scrape_by_act(\n",
    "            dataset['train'],\n",
    "            dataset['train_cond_vals'],\n",
    "            one_hot_rep,\n",
    "            seqs_per_act,\n",
    "            sigma,\n",
    "            mu,\n",
    "            parents)\n",
    "        val_poses = scrape_by_act(\n",
    "            dataset['valid'],\n",
    "            dataset['val_cond_vals'],\n",
    "            one_hot_rep,\n",
    "            seqs_per_act,\n",
    "            sigma,\n",
    "            mu,\n",
    "            parents)\n",
    "        \n",
    "        smooth_sampled_times = smooth_seq(\n",
    "            real_X.reshape(real_X.shape[:2] + (16,))\n",
    "        ).reshape(real_X.shape[:2] + (2, 8))\n",
    "        actn = sanitise_name(act_name)\n",
    "        dest_pfx = os.path.join(dest_dir, 'act-%s' % actn)\n",
    "        dest_fn = dest_pfx + '.npz'\n",
    "        print('Saving ' + dest_fn)\n",
    "        np.savez(\n",
    "            dest_fn, poses_gen=real_X,\n",
    "            poses_smooth=smooth_sampled_times,\n",
    "            poses_train=train_poses,\n",
    "            poses_val=val_poses,\n",
    "            parents=parents\n",
    "        )\n",
    "\n",
    "    # now choose random pairs of (distinct) actions and simulate\n",
    "    # a transition at half-way point\n",
    "    num_pairs = 10\n",
    "    nacts = len(act_names)\n",
    "    chosen_idxs = np.random.permutation(nacts * (nacts-1))[:num_pairs]\n",
    "    act_pairs = [(act_names[idxp%nacts], act_names[idxp//nacts]) \\\n",
    "                 for idxp in chosen_idxs]\n",
    "    for act1, act2 in act_pairs:\n",
    "        print('Computing sequence for action %s -> %s' % (act1, act2))\n",
    "        \n",
    "        len1 = seq_length // 2\n",
    "        len2 = seq_length - len1\n",
    "        rep1 = one_hot_acts[act1]\n",
    "        rep2 = one_hot_acts[act2]\n",
    "        U = np.stack([rep1] * len1 + [rep2] * len2, axis=0)\n",
    "        oodles_of_samples = dkf.sample(nsamples=seqs_per_act, T=seq_length, U=U)\n",
    "        sample_X, sample_Z = oodles_of_samples\n",
    "        mu = dataset['p2d_mean'].reshape((1, 1, -1))\n",
    "        sigma = dataset['p2d_std'].reshape((1, 1, -1))\n",
    "        real_X = p2d_loader.reconstruct_poses(sample_X * sigma + mu, parents)\n",
    "        \n",
    "        smooth_sampled_times = smooth_seq(\n",
    "            real_X.reshape(real_X.shape[:2] + (16,))\n",
    "        ).reshape(real_X.shape[:2] + (2, 8))\n",
    "        act1n = sanitise_name(act1)\n",
    "        act2n = sanitise_name(act2)\n",
    "        dest_pfx = os.path.join(\n",
    "            dest_dir,\n",
    "            'trans-%s-to-%s' % (act1n, act2n))\n",
    "        dest_fn = dest_pfx + '.npz'\n",
    "        print('Saving ' + dest_fn)\n",
    "        np.savez(\n",
    "            dest_fn,\n",
    "            poses_trans=sampled_times,\n",
    "            poses_trans_smooth=smooth_sampled_times,\n",
    "            parents=parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
